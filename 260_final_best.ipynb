{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/ver6.1/psc/dataHandling.py:20: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/ver6.1/psc/dataHandling.py:20: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import warnings\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import tree\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from datetime import datetime\n",
    "from sagemaker import get_execution_role\n",
    "from dataHandling import dataHandling\n",
    "from batchTools import batchTools\n",
    "from gruDataReshaper import gruDataReshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "DIRHOME = \"s3://sagemaker-begas-upload/marketCaster/ver2.4.3\"\n",
    "DAILY_DATE = \"2019-10-31\"\n",
    "BATCH_DATE = \"2020-01-07\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctDate(DF, nAhead):\n",
    "    tmpDATEDF = DF.copy()\n",
    "    tmpDATEDF['train_end']=tmpDATEDF['train_end'].apply(lambda x: pd.date_range(x, periods=2, freq='-{}B'.format(nAhead)).strftime('%Y-%m-%d')[1])\n",
    "    tmpDATEDF['train_start']=tmpDATEDF['train_start'].apply(lambda x: pd.date_range(x, periods=2, freq='-{}B'.format(nAhead)).strftime('%Y-%m-%d')[1])\n",
    "    tmpDATEDF['valid_end']=tmpDATEDF['valid_end'].apply(lambda x: pd.date_range(x, periods=2, freq='-{}B'.format(nAhead)).strftime('%Y-%m-%d')[1])\n",
    "    tmpDATEDF['valid_start']=tmpDATEDF['valid_start'].apply(lambda x: pd.date_range(x, periods=2, freq='-{}B'.format(nAhead)).strftime('%Y-%m-%d')[1])\n",
    "    return tmpDATEDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(y_true, y_pred):\n",
    "    mean_true = tf.math.reduce_mean(y_true)\n",
    "    mean_pred = tf.math.reduce_mean(y_pred)\n",
    "    \n",
    "    std_true = tf.math.reduce_std(y_true)\n",
    "    std_pred = tf.math.reduce_std(y_pred)\n",
    "    \n",
    "    up = tf.reduce_mean(tf.math.multiply((y_true-mean_true), (y_pred-mean_pred)))\n",
    "    down = std_true * std_pred\n",
    "    corr = 1.0-tf.compat.v1.where(tf.math.is_nan(up/down),0.0,up/down)\n",
    "    \n",
    "    \n",
    "    meanerr = tf.math.sqrt(tf.math.square(mean_true - mean_pred))\n",
    "    mserr = tf.math.sqrt(tf.math.reduce_mean(tf.math.square(y_true-y_pred)))\n",
    "    signerr = 1-tf.math.reduce_mean(tf.math.multiply(tf.math.sign(y_true), tf.math.sign(y_pred)))\n",
    "    \n",
    "    return mserr + corr/2 + signerr/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelgen(nTimeSteps, nFeature):\n",
    "    layer_input = keras.Input(shape=(nTimeSteps, nFeature), name='input')\n",
    "    layer_state = keras.layers.CuDNNGRU(units=100, return_state=True, name='gru_cell_0')(layer_input)[1]\n",
    "    layer_gru = keras.layers.CuDNNGRU(units=100, return_sequences=True, name='gru_cell_1')(layer_input, initial_state=layer_state)\n",
    "    layer_gru = keras.layers.CuDNNGRU(units=100, return_sequences=True, name='gru_cell_2')(layer_gru)\n",
    "    layer_output = keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(units=1, activation='linear',\n",
    "                          kernel_regularizer=keras.regularizers.l2(l=0.01),\n",
    "                          kernel_initializer=tf.keras.initializers.Orthogonal(seed=925)), name='output')(layer_gru) \n",
    "    gru_model = keras.Model(layer_input, layer_output)\n",
    "    gru_model.compile(loss=customLoss, optimizer=keras.optimizers.Adam())\n",
    "    return gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailDir = '/out/performance_ver2.0/2020-03-03/{}/{:03}/final_best'\n",
    "GPUDEVICE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEDF = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()), 'out/dateDF.csv'))\n",
    "DATEDF.sort_values(by='test_end', inplace=True)\n",
    "DATEDF.reset_index(drop=True, inplace=True)\n",
    "AHEAD=260\n",
    "TOTFEATURE = 80\n",
    "SELFEATURE = 65\n",
    "TIMESTEPS = 40\n",
    "TIMEUNIT = 10\n",
    "NTREE = 10\n",
    "DATEDF = correctDate(DATEDF, AHEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowork(stage):\n",
    "    VALID_START = DATEDF.iloc[stage,0]\n",
    "    VALID_END = DATEDF.iloc[stage,1]\n",
    "    TRAIN_START = DATEDF.iloc[stage,2]\n",
    "    TRAIN_END = DATEDF.iloc[stage,3]\n",
    "    TEST_START = DATEDF.iloc[stage,4]\n",
    "    TEST_END = DATEDF.iloc[stage,5]\n",
    "\n",
    "    # Read Data\n",
    "    dataHandler = dataHandling(DIRHOME, MARKET, AHEAD)\n",
    "    dataHandler.readConvertedData(TEST_END)\n",
    "    dataHandler.readVarImpData(1000, TEST_END)\n",
    "    dataHandler.readRawData(DAILY_DATE)\n",
    "    dataHandler.readEDAData(DAILY_DATE)\n",
    "    dataHandler.slicingData()\n",
    "    dataHandler.naRemover()\n",
    "\n",
    "    # Variable Selection\n",
    "    varImpDF = dataHandler.varImpDF.copy()\n",
    "    varImpDF = varImpDF[['var_name', 'correlation','impurity', 'SSE', 'matching_score', 'non_zero_number', 'rank_total']]\n",
    "    varImpDF['score_1'] = (abs(varImpDF[['correlation']])-abs(varImpDF[['correlation']]).mean())/abs(varImpDF[['correlation']]).std()\n",
    "    varImpDF['score_2'] = (varImpDF[['impurity']]-varImpDF[['impurity']].mean())/varImpDF[['impurity']].std()\n",
    "    varImpDF['score_3'] = -(varImpDF[['SSE']]-varImpDF[['SSE']].mean())/(varImpDF[['SSE']].std())\n",
    "    varImpDF['score_4'] = -(varImpDF[['matching_score']]-varImpDF[['matching_score']].mean())/varImpDF[['matching_score']].std()\n",
    "    varImpDF['score_5'] = (varImpDF[['non_zero_number']]-varImpDF[['non_zero_number']].mean())/varImpDF[['non_zero_number']].std()\n",
    "    varImpDF['score'] = varImpDF[['score_1','score_2','score_3','score_4','score_5']].mean(1)\n",
    "    varImpDF.sort_values('score', ascending=False, inplace=True)\n",
    "    xVarsNew = varImpDF['var_name'][:TOTFEATURE].tolist()\n",
    "\n",
    "    # To Numpy\n",
    "    grudatareshaper = gruDataReshaper(dataHandler.convertedDF, \n",
    "                              AHEAD, \n",
    "                              dataHandler.yVar, \n",
    "                              xVarsNew, \n",
    "                              pd.date_range(TRAIN_START, periods=2, freq='-{}B'.format(TIMESTEPS*TIMEUNIT)).strftime('%Y-%m-%d')[1], \n",
    "                              TRAIN_END)\n",
    "    grudatareshaper.minmaxNormalization()\n",
    "    grudatareshaper.normalizedDF = grudatareshaper.normalizedDF.loc[grudatareshaper.normalizedDF.date_frct<=TEST_END]\n",
    "    grudatareshaper.normalizedDF.reset_index(drop=True, inplace=True)\n",
    "    dateDF, xNP, yNP = grudatareshaper.toNumpy(TIMEUNIT, TIMESTEPS, bNormal=True, bYOn=True)\n",
    "    print(xNP.shape)\n",
    "    # Seperate Data\n",
    "    trainXNP = xNP[(dateDF['date_frct']>=TRAIN_START)&(dateDF['date_frct']<=TRAIN_END),:,:]\n",
    "    trainYNP = yNP[(dateDF['date_frct']>=TRAIN_START)&(dateDF['date_frct']<=TRAIN_END),:,:]\n",
    "    validXNP = xNP[(dateDF['date_frct']>=VALID_START)&(dateDF['date_frct']<=VALID_END),:,:]\n",
    "    validYNP = yNP[(dateDF['date_frct']>=VALID_START)&(dateDF['date_frct']<=VALID_END),:,:]\n",
    "    testXNP = xNP[(dateDF['date_frct']>=TEST_START)&(dateDF['date_frct']<=TEST_END),:,:]\n",
    "    testYNP = yNP[(dateDF['date_frct']>=TEST_START)&(dateDF['date_frct']<=TEST_END),:,:]\n",
    "    flagDateDF = dateDF.loc[(dateDF['date_frct']>=TEST_START)&(dateDF['date_frct']<=TEST_END)]\n",
    "    dateDF = dateDF.loc[(dateDF['date_frct']>=VALID_START)]\n",
    "\n",
    "    # Random Forest (Variable Sampling)\n",
    "    colNumLT = [np.random.choice(TOTFEATURE, SELFEATURE, replace=False) for x in range(NTREE)]\n",
    "\n",
    "    with tf.device('/gpu:{}'.format(GPUDEVICE)):\n",
    "        # gpu setting\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth=True\n",
    "        sess = tf.Session(config=config)  \n",
    "        tf.keras.backend.set_session(sess)\n",
    "        tf.set_random_seed(925)\n",
    "        # Model + Training\n",
    "        modelLT = [modelgen(TIMESTEPS, SELFEATURE) for x in range(NTREE)]\n",
    "        earlyStop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=30)\n",
    "        tf.set_random_seed(925)\n",
    "        for x in range(NTREE):\n",
    "            print('[ Model {:02} ]'.format(x))\n",
    "            modelLT[x].fit(trainXNP[:,:,colNumLT[x]], trainYNP,\n",
    "                           validation_data = (validXNP[:,:,colNumLT[x]], validYNP),\n",
    "                           batch_size=50,\n",
    "                           epochs=200,\n",
    "                           callbacks=[earlyStop],\n",
    "                           verbose=0)\n",
    "            print('  - complete!\\n')    \n",
    "\n",
    "        # Compute Training Error\n",
    "        err = [((modelLT[x].predict(trainXNP[:,:,colNumLT[x]])[:,-1,-1]-trainYNP[:,-1,-1])**2).sum() for x in range(10)]\n",
    "        weight = (1-np.array(err))/(1-np.array(err)).sum()\n",
    "\n",
    "        for x in range(10):\n",
    "            inputs = np.where(testXNP[:,:,colNumLT[x]]>1,1,testXNP[:,:,colNumLT[x]])\n",
    "            inputs = np.where(inputs<0, 0, inputs)\n",
    "            if x==0:\n",
    "                prediction0 = modelLT[x].predict(inputs)[:,-1,-1] * weight[x]\n",
    "                prediction1 = modelLT[x].predict(testXNP[:,:,colNumLT[x]])[:,-1,-1] * weight[x]\n",
    "            else:\n",
    "                prediction0 += modelLT[x].predict(inputs)[:,-1,-1] * weight[x]\n",
    "                prediction1 += modelLT[x].predict(testXNP[:,:,colNumLT[x]])[:,-1,-1] * weight[x]\n",
    "\n",
    "        prediction = prediction0*0.8 + prediction1*0.2\n",
    "        #tf.keras.backend.clear_session()\n",
    "\n",
    "    ## Save\n",
    "    predDF = flagDateDF.copy()\n",
    "    predDF['prediction'] = prediction\n",
    "    tmpY = re.sub('_last_[0-9]{3}$|_last_[0-9]{2}$|_last_[0-9]{1}$','_last', dataHandler.yVar[0])\n",
    "    predDF = predDF.merge(dataHandler.rawDF.rename(columns={'date':'date_base',\n",
    "                                                           tmpY:'y_base'}), 'left')\n",
    "    tmp = dataHandler.rawDF.rename(columns={'date':'date_frct',tmpY:'y_frct'})\n",
    "    tmp['moving_std'] = tmp['y_frct'].rolling(window=int(np.where(AHEAD==1, 5, AHEAD))).std()\n",
    "    tmp['lower_bound_accuracy'] = tmp['y_frct'] - 1.644854*tmp['moving_std']\n",
    "    tmp['upper_bound_accuracy'] = tmp['y_frct'] + 1.644854*tmp['moving_std']\n",
    "    tmp = tmp[['date_frct', 'y_frct', 'lower_bound_accuracy', 'upper_bound_accuracy']]\n",
    "    predDF = predDF.merge(tmp, 'left')\n",
    "\n",
    "    batchtools = batchTools('2020-01-16')\n",
    "    predDF = batchtools.reconvertData(tmpY, predDF, dataHandler.edaDF)\n",
    "    ## Save - Path\n",
    "    saveDir = os.path.dirname(os.getcwd()) + detailDir.format(MARKET,AHEAD) \n",
    "    if not os.path.isdir(saveDir):\n",
    "        os.makedirs(saveDir)\n",
    "    predDF.sort_values(by=['date_frct'], inplace=True)\n",
    "    predDF.to_csv(saveDir+'/stage_{:03}.csv'.format(stage),index=False)\n",
    "    print('    - Complete!\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kospi_index\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:54) [ Read Converted Data ]\n",
      "(2020-03-04 15:00:58) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:00:58) [ Read Raw Data ]\n",
      "(2020-03-04 15:00:58) [ Read EDA Data ]\n",
      "(2020-03-04 15:00:58) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:00:58) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:00:59) [ Read Raw Data ]\n",
      "(2020-03-04 15:00:59) [ Read EDA Data ]\n",
      "(2020-03-04 15:00:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:00:59) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:00:59) [ Read Raw Data ]\n",
      "(2020-03-04 15:00:59) [ Read Variables Importance Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:00:59) [ Read EDA Data ]\n",
      "(2020-03-04 15:00:59) [ Read Raw Data ]\n",
      "(2020-03-04 15:00:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:00:59) [ Read EDA Data ]\n",
      "(2020-03-04 15:00:59) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:00:59) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:00:59) [ Read Raw Data ]\n",
      "(2020-03-04 15:00:59) [ Read EDA Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:00:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:00:59) [ Read Variables Importance Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:00:59) [ Read Raw Data ]\n",
      "(2020-03-04 15:00:59) [ Read EDA Data ]\n",
      "(2020-03-04 15:00:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:01:00) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:01:00) [ Read Raw Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:01:00) [ Read EDA Data ]\n",
      "(2020-03-04 15:01:00) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:01:00) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:01:00) [ Read Raw Data ]\n",
      "(2020-03-04 15:01:00) [ Read EDA Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:01:00) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(3354, 40, 80)\n",
      "(3419, 40, 80)\n",
      "(3679, 40, 80)\n",
      "(3744, 40, 80)\n",
      "(3484, 40, 80)\n",
      "(3809, 40, 80)\n",
      "(3614, 40, 80)\n",
      "(3549, 40, 80)\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:14:46) [ Read Converted Data ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "(2020-03-04 15:14:51) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:14:51) [ Read Raw Data ]\n",
      "(2020-03-04 15:14:51) [ Read EDA Data ]\n",
      "(2020-03-04 15:14:51) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(3874, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:16:15) [ Read Converted Data ]\n",
      "(2020-03-04 15:16:20) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:16:20) [ Read Raw Data ]\n",
      "(2020-03-04 15:16:20) [ Read EDA Data ]\n",
      "(2020-03-04 15:16:20) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "(3939, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:17:40) [ Read Converted Data ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "(2020-03-04 15:17:45) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:17:45) [ Read Raw Data ]\n",
      "(2020-03-04 15:17:45) [ Read EDA Data ]\n",
      "(2020-03-04 15:17:45) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(4004, 40, 80)\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:20:13) [ Read Converted Data ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "(2020-03-04 15:20:18) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:20:18) [ Read Raw Data ]\n",
      "(2020-03-04 15:20:18) [ Read EDA Data ]\n",
      "(2020-03-04 15:20:18) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(4069, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:24:12) [ Read Converted Data ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "(2020-03-04 15:24:18) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:24:18) [ Read Raw Data ]\n",
      "(2020-03-04 15:24:18) [ Read EDA Data ]\n",
      "(2020-03-04 15:24:18) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "(4134, 40, 80)\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:24:33) [ Read Converted Data ]\n",
      "[ Model 00 ]\n",
      "(2020-03-04 15:24:37) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:24:37) [ Read Raw Data ]\n",
      "(2020-03-04 15:24:37) [ Read EDA Data ]\n",
      "(2020-03-04 15:24:37) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "(4199, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:27:48) [ Read Converted Data ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:27:53) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:27:53) [ Read Raw Data ]\n",
      "(2020-03-04 15:27:53) [ Read EDA Data ]\n",
      "(2020-03-04 15:27:53) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Complete!\n",
      " \n",
      "(4264, 40, 80)\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "[ Model 00 ]\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "spx_index\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:07) [ Read Converted Data ]\n",
      "(2020-03-04 15:36:11) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:11) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:11) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:11) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:36:12) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:12) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:12) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:12) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:12) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:12) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:36:12) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:12) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:12) [ Read EDA Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:36:12) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:12) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:36:12) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "\n",
      "(2020-03-04 15:36:12) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:12) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:12) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:36:12) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:12) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:12) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:12) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:12) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:12) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:12) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:36:13) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:36:13) [ Remove Non-Available Data ]\n",
      "(2020-03-04 15:36:13) [ Read Variables Importance Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "                        * 260 rows are removed!\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "\n",
      "(2020-03-04 15:36:13) [ Read Raw Data ]\n",
      "(2020-03-04 15:36:13) [ Read EDA Data ]\n",
      "(2020-03-04 15:36:13) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(3354, 40, 80)\n",
      "(3549, 40, 80)\n",
      "(3614, 40, 80)\n",
      "(3809, 40, 80)\n",
      "(3484, 40, 80)\n",
      "(3679, 40, 80)\n",
      "(3419, 40, 80)\n",
      "(3744, 40, 80)\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:45:02) [ Read Converted Data ]\n",
      "(2020-03-04 15:45:08) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:45:08) [ Read Raw Data ]\n",
      "(2020-03-04 15:45:08) [ Read EDA Data ]\n",
      "(2020-03-04 15:45:08) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(3874, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:52:25) [ Read Converted Data ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:52:27) [ Read Converted Data ]\n",
      "(2020-03-04 15:52:29) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:52:29) [ Read Raw Data ]\n",
      "(2020-03-04 15:52:29) [ Read EDA Data ]\n",
      "(2020-03-04 15:52:29) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:52:30) [ Read Converted Data ]\n",
      "(2020-03-04 15:52:31) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:52:31) [ Read Raw Data ]\n",
      "(2020-03-04 15:52:31) [ Read EDA Data ]\n",
      "(2020-03-04 15:52:31) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(2020-03-04 15:52:35) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:52:35) [ Read Raw Data ]\n",
      "(2020-03-04 15:52:35) [ Read EDA Data ]\n",
      "(2020-03-04 15:52:35) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:52:37) [ Read Converted Data ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(3939, 40, 80)\n",
      "(2020-03-04 15:52:42) [ Read Variables Importance Data ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2020-03-04 15:52:42) [ Read Raw Data ]\n",
      "(2020-03-04 15:52:42) [ Read EDA Data ]\n",
      "(2020-03-04 15:52:42) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(4004, 40, 80)\n",
      "[ Model 00 ]\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "[ Model 00 ]\n",
      "(4069, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "(4134, 40, 80)\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:55:20) [ Read Converted Data ]\n",
      "    - Complete!\n",
      " \n",
      "(2020-03-04 15:55:21) [ Read Converted Data ]\n",
      "(2020-03-04 15:55:24) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:55:25) [ Read Raw Data ]\n",
      "(2020-03-04 15:55:25) [ Read EDA Data ]\n",
      "(2020-03-04 15:55:25) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 15:55:26) [ Read Variables Importance Data ]\n",
      "(2020-03-04 15:55:27) [ Read Raw Data ]\n",
      "(2020-03-04 15:55:27) [ Read EDA Data ]\n",
      "(2020-03-04 15:55:27) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(4199, 40, 80)\n",
      "(4264, 40, 80)\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 02 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 03 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 04 ]\n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 05 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 06 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 07 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 08 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "[ Model 09 ]\n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "  - complete!\n",
      "\n",
      "  - complete!\n",
      "\n",
      "    - Complete!\n",
      " \n",
      "    - Complete!\n",
      " \n",
      "    - Complete!\n",
      " \n",
      "cl1_comdty\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:54) [ Read Converted Data ]\n",
      "(2020-03-04 16:12:57) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:58) [ Read Raw Data ]\n",
      "(2020-03-04 16:12:58) [ Read EDA Data ]\n",
      "(2020-03-04 16:12:58) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 16:12:58) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:58) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:58) [ Read Raw Data ]\n",
      "(2020-03-04 16:12:59) [ Read EDA Data ]\n",
      "(2020-03-04 16:12:59) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:59) [ Read Raw Data ]\n",
      "(2020-03-04 16:12:59) [ Read EDA Data ]\n",
      "(2020-03-04 16:12:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 16:12:59) [ Read Raw Data ]\n",
      "(2020-03-04 16:12:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 16:12:59) [ Read EDA Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 16:12:59) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:59) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 16:12:59) [ Read Raw Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 16:12:59) [ Read EDA Data ]\n",
      "(2020-03-04 16:12:59) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:59) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:12:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 16:12:59) [ Read Raw Data ]\n",
      "(2020-03-04 16:12:59) [ Read Raw Data ]\n",
      "                        * 260 rows are removed!\n",
      "(2020-03-04 16:12:59) [ Read EDA Data ]\n",
      "\n",
      "(2020-03-04 16:12:59) [ Read EDA Data ]\n",
      "(2020-03-04 16:12:59) [ Remove Non-Available Data ]\n",
      "(2020-03-04 16:12:59) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "(2020-03-04 16:13:00) [ Read Variables Importance Data ]\n",
      "(2020-03-04 16:13:00) [ Read Raw Data ]\n",
      "(2020-03-04 16:13:00) [ Read EDA Data ]\n",
      "(2020-03-04 16:13:00) [ Remove Non-Available Data ]\n",
      "                        * 260 rows are removed!\n",
      "\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "    - Reshape Data (converting data frame to numpy.)\n",
      "(3354, 40, 80)\n",
      "(3484, 40, 80)\n",
      "(3419, 40, 80)\n",
      "(3549, 40, 80)\n",
      "(3614, 40, 80)\n",
      "(3809, 40, 80)\n",
      "(3679, 40, 80)\n",
      "(3744, 40, 80)\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "[ Model 00 ]\n",
      "  - complete!\n",
      "\n",
      "[ Model 01 ]\n"
     ]
    }
   ],
   "source": [
    "for MARKET in ['kospi_index','spx_index','cl1_comdty','xau_curncy','shcomp_index','dxy_curncy',\n",
    "               'gtkrw10y_corp','gtusd10y_govt','gtcny10y_corp']:\n",
    "    print(MARKET)\n",
    "    pool = multiprocessing.Pool(processes=8)\n",
    "    pool.map(dowork, np.arange(15))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
